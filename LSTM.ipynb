{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e045584e",
   "metadata": {},
   "source": [
    "## Implement LSTM to verify PyTorch  APIs of LSTM, LSTM projection, and GRU\n",
    "Reference: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "`CLASStorch.nn.LSTM(*args, **kwargs)`\n",
    "\n",
    "Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. For each element in the input sequence, each layer computes the following function:\n",
    "\\begin{align*}\n",
    "i_t&=\\sigma(W_{ii}x_t+b_{ii}+W_{hi}h_{t-1}+b_{hi})\\\\\n",
    "f_t&=\\sigma(W_{if}x_t+b_{if}+W_{hf}h_{t-1}+b_{hf})\\\\\n",
    "g_t&=\\tanh(W_{ig}x_t+b_{ig}+W_{hg}h_{t-1}+b_{hg})\\\\\n",
    "o_t&=\\sigma(W_{io}x_t+b_{io}+W_{ho}h_{t-1}+b_{ho})\\\\\n",
    "c_t&=f_t\\odot c_{t-1}+i_t\\odot g_t\\\\\n",
    "h_t&=o_t\\odot\\tanh(c_t)\n",
    "\\end{align*}\n",
    "where $h_t$ is the hidden state at time $t$, $c_t$ is the cell state at time $t$, $x_t$ is the input at time $t$, $h_{t-1}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time $0$, and $i_t$, $f_t$, $g_t$, $o_t$ are the input, forget, cell, and output gates, respectively. $\\sigma$ is the sigmoid function, and $\\odot$ is the Hadamard product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dce24ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5]) torch.Size([1, 2, 5]) torch.Size([1, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "bs, T, i_size, h_size = 2, 3, 4, 5\n",
    "D = 1\n",
    "num_layers = 1\n",
    "data = torch.randn(bs, T, i_size)\n",
    "c0 = torch.randn(D*num_layers, bs, h_size) # initial states, see API doc for the dimension requirement\n",
    "h0 = torch.randn(D*num_layers, bs, h_size)\n",
    "\n",
    "# call PyTorch APIs\n",
    "lstm_layer = nn.LSTM(i_size, h_size, batch_first=True) # instantiate an LSTM class\n",
    "output, (h_final, c_final) = lstm_layer(data, (h0,c0))\n",
    "print(output.shape,h_final.shape,c_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da2fc2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([20, 4])\n",
      "weight_hh_l0 torch.Size([20, 5])\n",
      "bias_ih_l0 torch.Size([20])\n",
      "bias_hh_l0 torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for n,p in lstm_layer.named_parameters():\n",
    "    print(n,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45e94215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    }
   ],
   "source": [
    "# write a LSTM function\n",
    "def lstm_forward(data, initial_states, w_ih, w_hh, b_ih, b_hh):\n",
    "    h0, c0 = initial_states\n",
    "    bs, T, i_size = data.shape\n",
    "    h_size = w_ih.shape[0]//4 # there are 4 groups of parameters\n",
    "    prev_h = h0\n",
    "    prev_c = c0\n",
    "    batch_w_ih = w_ih.unsqueeze(0).tile(bs, 1, 1) # [bs,(4*h_size),i_size]\n",
    "    batch_w_hh = w_hh.unsqueeze(0).tile(bs, 1, 1) # [bs,(4*h_size),i_size]\n",
    "    \n",
    "    output_size = h_size\n",
    "    output_h = torch.zeros(bs,T,output_size)\n",
    "    for t in range(T):\n",
    "        x = data[:, t, :] # get the data of the current time step\n",
    "        w_times_x = torch.bmm(batch_w_ih, x.unsqueeze(-1)) # unsqueeze x because batch 2 must be 3D tensor\n",
    "        w_times_prev_h = torch.bmm(batch_w_hh, prev_h.reshape(bs,h_size).unsqueeze(-1))# reshape into [bs,h_size] and then unsqueeze  because batch 2 must be 3D tensor\n",
    "        all_before_activating = w_times_x.squeeze() + b_ih + w_times_prev_h.squeeze() + b_hh\n",
    "\n",
    "        # calculate the outputs of input, forget, cell, and output gates\n",
    "        i_t = torch.sigmoid(all_before_activating[:,:h_size])\n",
    "        f_t = torch.sigmoid(all_before_activating[:,h_size:2*h_size])\n",
    "        g_t = torch.tanh(all_before_activating[:,2*h_size:3*h_size])\n",
    "        o_t = torch.sigmoid(all_before_activating[:,3*h_size:])        \n",
    "        prev_c = f_t*prev_c + i_t*g_t\n",
    "        prev_h = o_t*torch.tanh(prev_c)\n",
    "        output_h[:,t,:] = prev_h\n",
    "        \n",
    "    return output_h, (prev_h,prev_c)        \n",
    "\n",
    "custom_lstm_output, (custom_h_final,custom_c_final) = lstm_forward(data,(h0,c0),\\\n",
    "                                                     lstm_layer.weight_ih_l0,\\\n",
    "                                                     lstm_layer.weight_hh_l0,\\\n",
    "                                                     lstm_layer.bias_ih_l0,\\\n",
    "                                                     lstm_layer.bias_hh_l0)\n",
    "# verify if our outputs are consistent with PyTorch APIs' outputs\n",
    "print(torch.allclose(custom_lstm_output, output),\\\n",
    "      torch.allclose(custom_h_final,h_final),\\\n",
    "      torch.allclose(custom_c_final,c_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b2e98",
   "metadata": {},
   "source": [
    "### LSTM projection\n",
    "This is used to compress `h`. We need to initialize `h` in `proj_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d8cccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3]) torch.Size([1, 2, 3]) torch.Size([1, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "proj_size = 3\n",
    "proj_h_0 = torch.randn(D*num_layers, bs, proj_size) # Note that only h_0 is in proj_size. c_0 is still in h_size.\n",
    "\n",
    "lstm_proj_layer = nn.LSTM(i_size, h_size, batch_first=True, proj_size=proj_size) # instantiate an LSTM class\n",
    "lstm_proj_output, (lstm_proj_final_h,lstm_proj_final_c) = lstm_proj_layer(data, (proj_h_0,c0))\n",
    "print(lstm_proj_output.shape,lstm_proj_final_h.shape,lstm_proj_final_c.shape) # c_n is still in h_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5fe89b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([20, 4])\n",
      "weight_hh_l0 torch.Size([20, 3])\n",
      "bias_ih_l0 torch.Size([20])\n",
      "bias_hh_l0 torch.Size([20])\n",
      "weight_hr_l0 torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "for n,p in lstm_proj_layer.named_parameters():\n",
    "    print(n,p.shape) # Besides the regular params, we will get weight_hr_l0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a0f9a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n",
      "torch.Size([1, 2, 3])\n",
      "torch.Size([1, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# write a LSTM function with an interface for projecting h to a lower dimension\n",
    "def lstm_forward(data, initial_states, w_ih, w_hh, b_ih, b_hh, w_hr=None):\n",
    "    h0, c0 = initial_states\n",
    "    bs, T, i_size = data.shape\n",
    "    h_size = w_ih.shape[0]//4 # there are 4 groups of parameters\n",
    "    prev_h = h0\n",
    "    prev_c = c0\n",
    "    batch_w_ih = w_ih.unsqueeze(0).tile(bs, 1, 1) # [bs,(4*h_size),i_size]\n",
    "    batch_w_hh = w_hh.unsqueeze(0).tile(bs, 1, 1) # [bs,(4*h_size),i_size]\n",
    "    \n",
    "    if w_hr is not None:\n",
    "        p_size = w_hr.shape[0]\n",
    "        output_size = p_size\n",
    "        batch_w_hr = w_hr.unsqueeze(0).tile(bs, 1, 1) # [bs,(4*h_size),i_size]\n",
    "    else:\n",
    "        output_size = h_size\n",
    "    \n",
    "    output_h = torch.zeros(bs,T,output_size)\n",
    "    for t in range(T):\n",
    "        x = data[:, t, :] # get the data of the current time step\n",
    "        w_times_x = torch.bmm(batch_w_ih, x.unsqueeze(-1)) # unsqueeze x because batch 2 must be 3D tensor\n",
    "        w_times_prev_h = torch.bmm(batch_w_hh, prev_h.reshape(bs,p_size).unsqueeze(-1))# reshape into [bs,h_size] and then unsqueeze  because batch 2 must be 3D tensor\n",
    "        all_before_activating = w_times_x.squeeze() + b_ih + w_times_prev_h.squeeze() + b_hh\n",
    "\n",
    "        # calculate the outputs of input, forget, cell, and output gates\n",
    "        i_t = torch.sigmoid(all_before_activating[:,:h_size])\n",
    "        f_t = torch.sigmoid(all_before_activating[:,h_size:2*h_size])\n",
    "        g_t = torch.tanh(all_before_activating[:,2*h_size:3*h_size])\n",
    "        o_t = torch.sigmoid(all_before_activating[:,3*h_size:])        \n",
    "        prev_c = f_t*prev_c + i_t*g_t\n",
    "        prev_h = o_t*torch.tanh(prev_c) \n",
    "        \n",
    "        if w_hr is not None:\n",
    "            prev_h = torch.bmm(batch_w_hr, prev_h.squeeze().unsqueeze(-1))\n",
    "            prev_h = prev_h.squeeze()\n",
    "            \n",
    "        output_h[:,t,:] = prev_h # output_h[:,t,:] is 2D\n",
    "        \n",
    "        \n",
    "    return output_h, (prev_h.reshape(1,bs,output_size),prev_c)        \n",
    "\n",
    "custom_lstm_p_output, (custom_lstm_p_h_final,custom_lstm_p_c_final) = lstm_forward(data,(proj_h_0,c0),\\\n",
    "                                                     lstm_proj_layer.weight_ih_l0,\\\n",
    "                                                     lstm_proj_layer.weight_hh_l0,\\\n",
    "                                                     lstm_proj_layer.bias_ih_l0,\\\n",
    "                                                     lstm_proj_layer.bias_hh_l0,\\\n",
    "                                                     lstm_proj_layer.weight_hr_l0)\n",
    "print(custom_lstm_p_output.shape)\n",
    "print(custom_lstm_p_h_final.shape)\n",
    "print(custom_lstm_p_c_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "436c070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(custom_lstm_p_output,lstm_proj_output), torch.allclose(custom_lstm_p_h_final,lstm_proj_final_h),\\\n",
    "torch.allclose(custom_lstm_p_c_final,lstm_proj_final_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c3a04",
   "metadata": {},
   "source": [
    "## GRU API\n",
    "Reference: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "        \n",
    "`CLASS torch.nn.GRU(*args, **kwargs)`\n",
    "\n",
    "Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. For each element in the input sequence, each layer computes the following function:\n",
    "\\begin{align*}\n",
    "r_t&=\\sigma(W_{ir}x_t+b_{ir}+W_{hr}h_{t-1}+b_{hr})\\\\\n",
    "z_t&=\\sigma(W_{iz}x_t+b_{iz}+W_{hz}h_{t-1}+b_{hz})\\\\\n",
    "n_t&=\\tanh(W_{in}x_t+b_{in}+W_{hn}h_{t-1}+b_{hn})\\\\\n",
    "h_t&=(1-z_t)*n_t+z_t*h_{t-1}\n",
    "\\end{align*}\n",
    "where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, $h_{t-1}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time $0$, and $r_t$, $z_t$, $n_t$, $o_t$ are the reset, update, and new gates, respectively. $\\sigma$ is the sigmoid function, and $\\odot$ is the Hadamard product.\n",
    "\n",
    "According to the formulae, it is clear that the number of parameters of GRU is 3/4 of the number of parameters of LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "44ff9cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5]) torch.Size([1, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "bs, T, i_size, h_size = 2, 3, 4, 5\n",
    "D = 1\n",
    "num_layers = 1\n",
    "data = torch.randn(bs, T, i_size)\n",
    "h0 = torch.randn(D*num_layers, bs, h_size) # initial states, see API doc for the dimension requirement\n",
    "\n",
    "# call PyTorch APIs\n",
    "gru_layer = nn.GRU(i_size, h_size, batch_first=True) # instantiate an LSTM class\n",
    "gru_output, gru_h_final = gru_layer(data, h0)\n",
    "print(gru_output.shape,gru_h_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47341015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([15, 4])\n",
      "weight_hh_l0 torch.Size([15, 5])\n",
      "bias_ih_l0 torch.Size([15])\n",
      "bias_hh_l0 torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "for n,p in gru_layer.named_parameters():\n",
    "    print(n,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aed15efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "# write a GRU forward function\n",
    "def gru_forward(data, initial_states, w_ih, w_hh, b_ih, b_hh):\n",
    "    h0 = initial_states\n",
    "    bs, T, i_size = data.shape\n",
    "    h_size = w_ih.shape[0]//3 # there are 3 groups of parameters\n",
    "    prev_h = h0\n",
    "    batch_w_ih = w_ih.unsqueeze(0).tile(bs, 1, 1) # [bs,(3*h_size),i_size]\n",
    "    batch_w_hh = w_hh.unsqueeze(0).tile(bs, 1, 1) # [bs,(3*h_size),i_size]\n",
    "    \n",
    "    output_size = h_size\n",
    "    output_h = torch.zeros(bs,T,output_size)\n",
    "    for t in range(T):\n",
    "        x = data[:, t, :] # get the data of the current time step\n",
    "        w_times_x = torch.bmm(batch_w_ih, x.unsqueeze(-1)) # unsqueeze x because batch 2 must be 3D tensor\n",
    "        w_times_prev_h = torch.bmm(batch_w_hh, prev_h.reshape(bs,h_size).unsqueeze(-1))# reshape into [bs,h_size] and then unsqueeze  because batch 2 must be 3D tensor\n",
    "        r_z_before_activating = w_times_x.squeeze()[:,:2*h_size] + b_ih[:2*h_size] + \\\n",
    "                                w_times_prev_h.squeeze()[:,:2*h_size] + b_hh[:2*h_size]\n",
    "\n",
    "        # calculate the outputs of reset, update, and new gates\n",
    "        r_t = torch.sigmoid(r_z_before_activating[:,:h_size])\n",
    "        z_t = torch.sigmoid(r_z_before_activating[:,h_size:2*h_size])\n",
    "        n_t = torch.tanh(w_times_x.squeeze()[:,2*h_size:] + b_ih[2*h_size:]+\\\n",
    "                         r_t*(w_times_prev_h.squeeze()[:,2*h_size:] + b_hh[2*h_size:]))       \n",
    "        prev_h = (1-z_t)*n_t + z_t*prev_h # h_t\n",
    "        output_h[:,t,:] = prev_h\n",
    "        \n",
    "    return output_h, prev_h      \n",
    "\n",
    "custom_gru_output, custom_gru_h_final = gru_forward(data,h0,\\\n",
    "                                                     gru_layer.weight_ih_l0,\\\n",
    "                                                     gru_layer.weight_hh_l0,\\\n",
    "                                                     gru_layer.bias_ih_l0,\\\n",
    "                                                     gru_layer.bias_hh_l0)\n",
    "# verify if our outputs are consistent with PyTorch APIs' outputs\n",
    "print(torch.allclose(custom_gru_output, gru_output),\\\n",
    "      torch.allclose(custom_gru_h_final, gru_h_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be93ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
